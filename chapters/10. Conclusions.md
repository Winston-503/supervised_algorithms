## Conclusions

The most popular supervised learning algorithms were described here (of course, there are others). As a conclusion, I want to describe the process of choosing an algorithm to solve a typical supervised learning task (classification or regression). It's very simple - you just need to answer two questions.

Is your data sparse? If yes, then you will have to use linear methods. This is usually an *SVM*, and with different kernels it will allow you to restore complex dependencies. Remember that linear methods require data preprocessing, which can be problematic in some cases.

If your data is dense, then you are more lucky. Now everything depends on their amount. If there are a lot of them, then use a *boosting*, otherwise - *random forest*. Both of these algorithms are powerful, resistant to noise and will show you a good quality, but they will take a long time to learn and predict. Also, remember that boosting is prone to overfitting.

| ![supervised_learinig_algorithm_selection.jpg](../img/supervised_learinig_algorithm_selection.jpg) |
|:--:|
| <b>Block diagram for algorithm selection</b>|

What does *a lot of data* mean? How much is it? Usually talk about a threshold value of *100 thousand samples*, but in any case, you can (and most likely will) try different algorithms.

This is just a recommendation, and you should try different algorithms with different hyperparameters to solve your task in the best way.